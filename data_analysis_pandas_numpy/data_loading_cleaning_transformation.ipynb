{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrVIyoK4w5kt"
      },
      "source": [
        "# Конспект: Загрузка, очистка и преобразование данных в Python\n",
        "\n",
        "Этот ноутбук охватывает ключевые этапы предварительной обработки данных с использованием `pandas`, `numpy` и стандартных возможностей Python.\n",
        "\n",
        "Используемые датасеты:\n",
        "- `merged_data.csv` — данные о продажах (столбцы: Warehouse Code, Order Quantity, Region Sales, Product Name, Customer Names и др.)\n",
        "- `online_retail_II.xlsx` — транзакции (листы: Year 2009-2010, Year 2010-2011)"
      ],
      "id": "ZrVIyoK4w5kt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92s_TCiyw5ky"
      },
      "outputs": [],
      "source": [
        "# Импорт библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "id": "92s_TCiyw5ky"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT29Xaurw5k0"
      },
      "source": [
        "## 1. Загрузка данных\n",
        "\n",
        "### О чём пойдёт речь:\n",
        "- `pd.read_csv()` — загрузка из CSV (локально и по URL)\n",
        "- `pd.read_excel()` — загрузка из Excel, выбор листа\n",
        "- `pd.read_json()` — загрузка из JSON\n",
        "- `pd.read_clipboard()` — из буфера обмена\n",
        "- `pd.DataFrame()` — создание вручную\n",
        "- Указание индекса, пропущенных значений, кодировки"
      ],
      "id": "MT29Xaurw5k0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIkpZFEOw5k1"
      },
      "source": [
        "### pandas.read_csv()\n",
        "\n",
        "**Описание**: Загружает данные из CSV-файла в DataFrame.\n",
        "\n",
        "**Параметры**:\n",
        "- `filepath_or_buffer`: путь к файлу (локальный или URL)\n",
        "- `index_col`: указать столбец как индекс\n",
        "- `na_values`: какие значения считать пропущенными\n",
        "- `encoding`: кодировка (часто 'utf-8', 'latin1' для Excel-экспорта)"
      ],
      "id": "GIkpZFEOw5k1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np63aaBZw5k1"
      },
      "outputs": [],
      "source": [
        "# Пример 1: Загрузка CSV-файла (предположим, файл в той же папке)\n",
        "df_csv = pd.read_csv('merged_data.csv',\n",
        "                     index_col=0,  # Первый пустой столбец как индекс\n",
        "                     na_values=['', 'N/A', 'NULL'])  # Дополнительные значения как NaN\n",
        "\n",
        "print(\"Размер данных:\", df_csv.shape)\n",
        "df_csv.head(2)"
      ],
      "id": "Np63aaBZw5k1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IczeUNyw5k1"
      },
      "source": [
        "### pandas.read_excel()\n",
        "\n",
        "**Описание**: Загружает данные из Excel-файла. Поддерживает несколько листов.\n",
        "\n",
        "**Параметры**:\n",
        "- `sheet_name`: имя листа или список имён\n",
        "- `engine`: 'openpyxl' для .xlsx, 'xlrd' для .xls (может потребоваться установка)"
      ],
      "id": "4IczeUNyw5k1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJsgeNUdw5k2"
      },
      "outputs": [],
      "source": [
        "# Пример 2: Загрузка одного листа из Excel\n",
        "df_excel_1 = pd.read_excel('online_retail_II.xlsx',\n",
        "                           sheet_name='Year 2009-2010',\n",
        "                           na_values=[''])\n",
        "\n",
        "print(\"Размер Year 2009-2010:\", df_excel_1.shape)\n",
        "df_excel_1.head(2)"
      ],
      "id": "YJsgeNUdw5k2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e1-0EdNw5k2"
      },
      "outputs": [],
      "source": [
        "# Пример 3: Загрузка нескольких листов\n",
        "dfs_excel = pd.read_excel('online_retail_II.xlsx',\n",
        "                          sheet_name=['Year 2009-2010', 'Year 2010-2011'],\n",
        "                          na_values=[''])\n",
        "\n",
        "# Обращение к каждому листу\n",
        "df_2009 = dfs_excel['Year 2009-2010']\n",
        "df_2010 = dfs_excel['Year 2010-2011']\n",
        "\n",
        "print(\"2009-2010:\", df_2009.shape)\n",
        "print(\"2010-2011:\", df_2010.shape)"
      ],
      "id": "5e1-0EdNw5k2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84x37qMtw5k3"
      },
      "source": [
        "### pandas.read_json()\n",
        "\n",
        "**Описание**: Загружает данные из JSON-файла. Формат должен быть табличным (список объектов).\n",
        "\n",
        "**Параметры**:\n",
        "- `orient`: как интерпретировать структуру (например, 'records')"
      ],
      "id": "84x37qMtw5k3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtpBWYD1w5k3"
      },
      "outputs": [],
      "source": [
        "# Пример 4: Загрузка из JSON (если есть)\n",
        "# Допустим, у нас есть файл sales.json в формате [ {\"col\": \"val\"}, ... ]\n",
        "# df_json = pd.read_json('sales.json', orient='records')\n",
        "\n",
        "# Закомментировано, так как файл не указан\n",
        "# print(df_json.head())"
      ],
      "id": "FtpBWYD1w5k3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK1nLenew5k4"
      },
      "source": [
        "### pandas.read_clipboard()\n",
        "\n",
        "**Описание**: Загружает данные из буфера обмена (удобно для копирования из Excel/Google Sheets).\n",
        "\n",
        "**Использование**: Скопируйте таблицу → выполните ячейку."
      ],
      "id": "qK1nLenew5k4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPVZgvJDw5k5"
      },
      "outputs": [],
      "source": [
        "# Пример 5: Загрузка из буфера обмена\n",
        "# df_clip = pd.read_clipboard(sep=',')  # Указать разделитель\n",
        "# print(df_clip.head())\n",
        "\n",
        "# Закомментировано — требует действий пользователя"
      ],
      "id": "HPVZgvJDw5k5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unFdk0qJw5k5"
      },
      "source": [
        "### Создание DataFrame вручную\n",
        "\n",
        "**Описание**: Полезно для тестирования или генерации справочных таблиц."
      ],
      "id": "unFdk0qJw5k5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U15gR8g2w5k5"
      },
      "outputs": [],
      "source": [
        "# Пример 6: Создание DataFrame вручную\n",
        "df_manual = pd.DataFrame({\n",
        "    'Warehouse Code': ['W001', 'W002'],\n",
        "    'Order Quantity': [100, 150],\n",
        "    'Region Sales': ['North', 'South']\n",
        "})\n",
        "\n",
        "print(\"Вручную созданный DataFrame:\")\n",
        "df_manual"
      ],
      "id": "U15gR8g2w5k5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnH5orC5w5k6"
      },
      "source": [
        "## 2. Очистка данных\n",
        "\n",
        "### О чём пойдёт речь:\n",
        "- Обнаружение и обработка пропущенных значений\n",
        "- Удаление и замена дубликатов\n",
        "- Исправление типов данных\n",
        "- Обработка выбросов (логически, без графиков)\n",
        "- Очистка строк: пробелы, регистр\n",
        "- Удаление столбцов/строк\n",
        "- Замена некорректных значений\n",
        "- Валидация данных (возраст, пол и т.д.)"
      ],
      "id": "jnH5orC5w5k6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xudmj--w5k6"
      },
      "source": [
        "### Обнаружение пропущенных значений"
      ],
      "id": "6Xudmj--w5k6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH0i8_aYw5k7"
      },
      "outputs": [],
      "source": [
        "# Используем df_csv из merged_data.csv\n",
        "\n",
        "# 1. Проверка пропусков\n",
        "print(\"Количество пропусков по столбцам (первые 10):\")\n",
        "print(df_csv.isna().sum().head(10))\n",
        "\n",
        "print(\"\\nОбщее количество пропусков:\", df_csv.isna().sum().sum())\n",
        "print(\"Процент пропусков: {:.2f}%\".format(df_csv.isna().sum().sum() / df_csv.size * 100))"
      ],
      "id": "CH0i8_aYw5k7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2BKKzkSw5k7"
      },
      "source": [
        "### Удаление строк/столбцов с пропусками"
      ],
      "id": "l2BKKzkSw5k7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0OsXN79w5k7"
      },
      "outputs": [],
      "source": [
        "# 2. Удаление строк с пропусками\n",
        "df_no_na_rows = df_csv.dropna()  # Все строки с NaN удаляются\n",
        "print(f\"После удаления строк с NaN: {df_no_na_rows.shape}\")\n",
        "\n",
        "# Удаление только если ВСЕ значения NaN\n",
        "df_csv.dropna(how='all', inplace=False)\n",
        "\n",
        "# Удаление, если NaN в определённых столбцах\n",
        "df_csv.dropna(subset=['Order Quantity', 'Unit Price'], inplace=False)"
      ],
      "id": "p0OsXN79w5k7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnPLUSrCw5k8"
      },
      "source": [
        "### Заполнение пропущенных значений"
      ],
      "id": "XnPLUSrCw5k8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBPMHswtw5k8"
      },
      "outputs": [],
      "source": [
        "# 3. Заполнение пропусков\n",
        "df_filled = df_csv.copy()\n",
        "\n",
        "# Заполнение константой\n",
        "df_filled['Region Sales'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Заполнение средним (только для числовых)\n",
        "df_filled['Order Quantity'].fillna(df_filled['Order Quantity'].mean(), inplace=True)\n",
        "\n",
        "# Медианой\n",
        "df_filled['Unit Price'].fillna(df_filled['Unit Price'].median(), inplace=True)\n",
        "\n",
        "# Модой (наиболее частое значение)\n",
        "df_filled['Warehouse Code'].fillna(df_filled['Warehouse Code'].mode()[0], inplace=True)\n",
        "\n",
        "# Продолжение вперёд (ffill) или назад (bfill)\n",
        "df_filled['Line Total'].fillna(method='ffill', inplace=True)  # Замена предыдущим значением\n",
        "\n",
        "print(\"Пропуски заполнены разными методами.\")"
      ],
      "id": "FBPMHswtw5k8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvyAIDDMw5k9"
      },
      "source": [
        "### Работа с дубликатами"
      ],
      "id": "cvyAIDDMw5k9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZmG9mDjw5k9"
      },
      "outputs": [],
      "source": [
        "# 4. Поиск дубликатов\n",
        "duplicates_all = df_csv.duplicated().sum()\n",
        "duplicates_subset = df_csv.duplicated(subset=['Warehouse Code', 'Order Quantity', 'year', 'month', 'day']).sum()\n",
        "\n",
        "print(f\"Полных дубликатов строк: {duplicates_all}\")\n",
        "print(f\"Дубликатов по ключевым полям: {duplicates_subset}\")\n",
        "\n",
        "# Удаление дубликатов\n",
        "df_no_dups = df_csv.drop_duplicates()  # Все дубли\n",
        "df_no_dups_subset = df_csv.drop_duplicates(subset=['Warehouse Code', 'Order Quantity', 'year', 'month', 'day'])\n",
        "\n",
        "print(f\"После удаления дубликатов: {df_no_dups.shape}\")"
      ],
      "id": "hZmG9mDjw5k9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me6dmpcDw5k-"
      },
      "source": [
        "### Приведение типов данных"
      ],
      "id": "Me6dmpcDw5k-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaAoqGYnw5k-"
      },
      "outputs": [],
      "source": [
        "# 5. Проверка типов\n",
        "print(\"Типы данных до преобразования:\")\n",
        "print(df_csv.dtypes[['Order Quantity', 'Unit Price', 'year', 'month']].head())\n",
        "\n",
        "# Приведение к числовым\n",
        "df_csv['Order Quantity'] = pd.to_numeric(df_csv['Order Quantity'], errors='coerce')\n",
        "df_csv['Unit Price'] = pd.to_numeric(df_csv['Unit Price'], errors='coerce')\n",
        "\n",
        "# Приведение к строке\n",
        "df_csv['Warehouse Code'] = df_csv['Warehouse Code'].astype('string')\n",
        "\n",
        "# Дата из year, month, day\n",
        "df_csv['Date'] = pd.to_datetime(df_csv[['year', 'month', 'day']])\n",
        "\n",
        "print(\"\\nТипы после преобразования:\")\n",
        "print(df_csv[['Order Quantity', 'Unit Price', 'Date']].dtypes)"
      ],
      "id": "xaAoqGYnw5k-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nop69Z74w5k-"
      },
      "source": [
        "### Очистка строк: пробелы и регистр"
      ],
      "id": "Nop69Z74w5k-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FKFDSkTw5k_"
      },
      "outputs": [],
      "source": [
        "# 6. Удаление пробелов и приведение к нижнему регистру\n",
        "if 'Region Sales' in df_csv.columns:\n",
        "    df_csv['Region Sales'] = df_csv['Region Sales'].str.strip().str.lower()\n",
        "\n",
        "print(\"Пример очистки строк (первые 5 значений 'Region Sales'):\")\n",
        "print(df_csv['Region Sales'].head())"
      ],
      "id": "5FKFDSkTw5k_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f8sNwMGw5k_"
      },
      "source": [
        "### Удаление столбцов и строк"
      ],
      "id": "_f8sNwMGw5k_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EtqAUl7w5k_"
      },
      "outputs": [],
      "source": [
        "# 7. Удаление ненужных столбцов (например, one-hot encoded)\n",
        "cols_to_drop = [col for col in df_csv.columns if 'Customer Names_' in col or 'Product Name_' in col]\n",
        "df_reduced = df_csv.drop(columns=cols_to_drop)\n",
        "\n",
        "print(f\"Удалено столбцов: {len(cols_to_drop)}\")\n",
        "print(f\"Осталось: {df_reduced.shape[1]} столбцов\")\n",
        "\n",
        "# Удаление строк по условию (например, Order Quantity <= 0)\n",
        "df_clean = df_reduced[df_reduced['Order Quantity'] > 0]"
      ],
      "id": "6EtqAUl7w5k_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNYsBx5Nw5lA"
      },
      "source": [
        "### Замена значений"
      ],
      "id": "cNYsBx5Nw5lA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY8hJz6qw5lA"
      },
      "outputs": [],
      "source": [
        "# 8. Замена значений\n",
        "df_clean['Region Sales'] = df_clean['Region Sales'].replace({\n",
        "    'north': 'Northern',\n",
        "    'south': 'Southern',\n",
        "    'east': 'Eastern',\n",
        "    'west': 'Western'\n",
        "})\n",
        "\n",
        "print(\"Пример замены значений:\")\n",
        "print(df_clean['Region Sales'].unique())"
      ],
      "id": "vY8hJz6qw5lA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8nvlmnTw5lB"
      },
      "source": [
        "### Обработка выбросов (IQR-метод)"
      ],
      "id": "_8nvlmnTw5lB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb5CfADVw5lB"
      },
      "outputs": [],
      "source": [
        "# 9. Удаление выбросов по Order Quantity и Unit Price\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "df_no_outliers = remove_outliers_iqr(df_clean, 'Order Quantity')\n",
        "df_no_outliers = remove_outliers_iqr(df_no_outliers, 'Unit Price')\n",
        "\n",
        "print(f\"После удаления выбросов: {df_no_outliers.shape[0]} строк\")"
      ],
      "id": "Hb5CfADVw5lB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9QFYtlWw5lB"
      },
      "source": [
        "### Валидация данных"
      ],
      "id": "g9QFYtlWw5lB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdNLUZtNw5lC"
      },
      "outputs": [],
      "source": [
        "# 10. Проверка корректности данных\n",
        "# Например, Unit Price не может быть отрицательным\n",
        "invalid_price = df_no_outliers[df_no_outliers['Unit Price'] < 0]\n",
        "if len(invalid_price) > 0:\n",
        "    print(f\"Найдено {len(invalid_price)} строк с отрицательной ценой.\")\n",
        "    df_no_outliers = df_no_outliers[df_no_outliers['Unit Price'] >= 0]\n",
        "\n",
        "# Проверка года\n",
        "valid_years = df_no_outliers['year'].between(2000, 2030)\n",
        "df_final = df_no_outliers[valid_years]\n",
        "\n",
        "print(\"Финальный размер после валидации:\", df_final.shape)"
      ],
      "id": "FdNLUZtNw5lC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW4pzdY0w5lC"
      },
      "source": [
        "## 3. Преобразование данных\n",
        "\n",
        "### О чём пойдёт речь:\n",
        "- Группировка: `groupby` + `agg`\n",
        "- Сводные таблицы: `pivot_table`\n",
        "- Трансформация формата: `melt`, `stack`\n",
        "- Объединение данных: `merge`, `concat`\n",
        "- Применение функций: `apply`, `map`, `lambda`\n",
        "- Условные вычисления: `np.where`, `loc`, `query`\n",
        "- Создание новых столбцов\n",
        "- Сортировка и индексация"
      ],
      "id": "OW4pzdY0w5lC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CmuSa_Kw5lC"
      },
      "source": [
        "### Группировка и агрегация"
      ],
      "id": "4CmuSa_Kw5lC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EECu5G8uw5lD"
      },
      "outputs": [],
      "source": [
        "# 1. Группировка по региону и агрегация\n",
        "grouped = df_final.groupby('Region Sales').agg({\n",
        "    'Order Quantity': ['sum', 'mean', 'count'],\n",
        "    'Unit Price': 'mean',\n",
        "    'Line Total': 'sum'\n",
        "}).round(2)\n",
        "\n",
        "grouped.columns = ['_'.join(col).strip() for col in grouped.columns]\n",
        "grouped = grouped.reset_index()\n",
        "\n",
        "print(\"Сводка по регионам:\")\n",
        "grouped.head()"
      ],
      "id": "EECu5G8uw5lD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPK5AOd1w5lD"
      },
      "source": [
        "### Сводные таблицы"
      ],
      "id": "nPK5AOd1w5lD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adoooQGlw5lZ"
      },
      "outputs": [],
      "source": [
        "# 2. Сводная таблица: продажи по региону и году\n",
        "pivot = pd.pivot_table(df_final,\n",
        "                       values='Line Total',\n",
        "                       index='Region Sales',\n",
        "                       columns='year',\n",
        "                       aggfunc='sum',\n",
        "                       fill_value=0)\n",
        "\n",
        "print(\"Сводная таблица по годам:\")\n",
        "pivot"
      ],
      "id": "adoooQGlw5lZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkMMG_Ovw5lZ"
      },
      "source": [
        "### Трансформация формата (melt)"
      ],
      "id": "lkMMG_Ovw5lZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8QKkGXiw5la"
      },
      "outputs": [],
      "source": [
        "# 3. Расплавление данных (melt)\n",
        "df_sample = df_final[['Region Sales', 'year', 'Order Quantity', 'Unit Price']].head(10)\n",
        "df_melted = pd.melt(df_sample,\n",
        "                    id_vars=['Region Sales', 'year'],\n",
        "                    value_vars=['Order Quantity', 'Unit Price'],\n",
        "                    var_name='Metric',\n",
        "                    value_name='Value')\n",
        "\n",
        "print(\"Расплавленные данные:\")\n",
        "df_melted.head()"
      ],
      "id": "T8QKkGXiw5la"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4komOJPw5la"
      },
      "source": [
        "### Объединение данных"
      ],
      "id": "Y4komOJPw5la"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQjEX-tyw5la"
      },
      "outputs": [],
      "source": [
        "# 4. Объединение двух частей Excel\n",
        "if 'Quantity' not in df_2009.columns:\n",
        "    df_2009 = df_2009.rename(columns={'Quantity': 'Order Quantity'})\n",
        "\n",
        "# Объединение по строкам\n",
        "df_combined_years = pd.concat([df_2009, df_2010], ignore_index=True)\n",
        "print(\"Объединено по годам:\", df_combined_years.shape)"
      ],
      "id": "VQjEX-tyw5la"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S59BWirw5la"
      },
      "source": [
        "### Применение функций"
      ],
      "id": "6S59BWirw5la"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssj12p9Ow5lb"
      },
      "outputs": [],
      "source": [
        "# 5. Применение функций\n",
        "df_final['Price_Category'] = df_final['Unit Price'].apply(lambda x: 'High' if x > 50 else 'Low')\n",
        "\n",
        "# Использование map для категорий\n",
        "region_map = {'Northern': 'N', 'Southern': 'S', 'Eastern': 'E', 'Western': 'W'}\n",
        "df_final['Region_Code'] = df_final['Region Sales'].map(region_map)\n",
        "\n",
        "print(\"Новые столбцы:\")\n",
        "df_final[['Unit Price', 'Price_Category', 'Region Sales', 'Region_Code']].head()"
      ],
      "id": "Ssj12p9Ow5lb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zrgb5nEow5lb"
      },
      "source": [
        "### Условные вычисления"
      ],
      "id": "Zrgb5nEow5lb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G102XFDiw5lb"
      },
      "outputs": [],
      "source": [
        "# 6. Условные вычисления\n",
        "df_final['Discount'] = np.where(df_final['Order Quantity'] > 100, 0.1, 0.05)  # 10% или 5%\n",
        "df_final['Final_Price'] = df_final['Unit Price'] * (1 - df_final['Discount'])\n",
        "\n",
        "print(\"Скидки и итоговая цена:\")\n",
        "df_final[['Order Quantity', 'Discount', 'Final_Price']].head()"
      ],
      "id": "G102XFDiw5lb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSjHC7p3w5lb"
      },
      "source": [
        "### Фильтрация и сортировка"
      ],
      "id": "wSjHC7p3w5lb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPumnzUEw5lc"
      },
      "outputs": [],
      "source": [
        "# 7. Фильтрация и сортировка\n",
        "filtered = df_final[\n",
        "    (df_final['Region Sales'] == 'Northern') &\n",
        "    (df_final['year'] == 2010)\n",
        "]\n",
        "\n",
        "sorted_data = filtered.sort_values(by='Line Total', ascending=False)\n",
        "\n",
        "print(\"Топ-5 продаж в Севере в 2010 году:\")\n",
        "sorted_data.head(5)[['Warehouse Code', 'Line Total']]"
      ],
      "id": "BPumnzUEw5lc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cYKVhBMw5lc"
      },
      "source": [
        "### Изменение индекса"
      ],
      "id": "6cYKVhBMw5lc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JH9VPM7w5lc"
      },
      "outputs": [],
      "source": [
        "# 8. Установка составного индекса\n",
        "df_indexed = df_final.set_index(['year', 'month', 'Region Sales'])\n",
        "df_reset = df_indexed.reset_index()  # Вернуть обратно\n",
        "\n",
        "print(\"Индекс изменён и восстановлен.\")"
      ],
      "id": "3JH9VPM7w5lc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrI7mpujw5lc"
      },
      "source": [
        "## Заключение\n",
        "\n",
        "Этот ноутбук охватывает полный цикл предварительной обработки данных:\n",
        "- Загрузка из различных источников\n",
        "- Глубокая очистка (пропуски, дубли, типы, выбросы)\n",
        "- Преобразование (группировка, сводные таблицы, объединение, условия)\n",
        "\n",
        "Все операции снабжены комментариями и примерами на реальных структурах данных.\n",
        "\n",
        "📌 **Совет**: Всегда сохраняйте оригинальные данные и делайте копии перед очисткой (`df.copy()`)."
      ],
      "id": "hrI7mpujw5lc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}