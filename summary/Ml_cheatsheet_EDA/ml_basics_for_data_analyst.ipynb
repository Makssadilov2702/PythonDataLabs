{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Основы машинного обучения для аналитика\n",
        "\n",
        "В этом ноутбуке мы разберём базовые шаги, которые нужны для первой модели машинного обучения.\n",
        "\n",
        "Мы пройдём через:\n",
        "1. Постановку задачи\n",
        "2. Разделение данных на Train/Test\n",
        "3. Кодирование категориальных признаков\n",
        "4. Масштабирование данных\n",
        "5. Оценку качества модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Постановка задачи ML\n",
        "Машинное обучение — это когда мы строим алгоритм, который учится на данных и потом может делать прогнозы.\n",
        "\n",
        "**Типы задач:**\n",
        "- **Классификация** — предсказываем категорию (например, 'купит' или 'не купит').\n",
        "- **Регрессия** — предсказываем число (например, цену квартиры).\n",
        "\n",
        "Для примера мы будем решать задачу **классификации** — предсказывать, купит ли клиент товар."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Создадим небольшой пример данных\n",
        "df = pd.DataFrame({\n",
        "    'city': ['Moscow', 'SPB', 'Moscow', 'Kazan'],\n",
        "    'age': [25, 32, 47, 51],\n",
        "    'bought': [1, 0, 1, 0]\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Разделение данных на Train/Test\n",
        "Мы делим данные на:\n",
        "- **Train** (обучающая выборка) — модель учится на этих данных.\n",
        "- **Test** (тестовая выборка) — проверяем, как модель работает на новых данных.\n",
        "\n",
        "Это нужно, чтобы понять, сможет ли модель обобщать знания, а не просто запоминать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Признаки и целевая переменная\n",
        "X = df[['city', 'age']]\n",
        "y = df['bought']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "X_train, X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Кодирование категориальных признаков\n",
        "Модели не умеют работать с текстом напрямую, поэтому нужно перевести категории в числа.\n",
        "\n",
        "Мы используем **One-Hot Encoding**: создаём отдельный столбец для каждой категории."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "X_train_encoded = ohe.fit_transform(X_train[['city']])\n",
        "X_test_encoded = ohe.transform(X_test[['city']])\n",
        "\n",
        "X_train_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Масштабирование данных\n",
        "Некоторые модели чувствительны к диапазону значений признаков.\n",
        "Масштабирование помогает привести их к одному масштабу.\n",
        "\n",
        "Мы используем **StandardScaler** — приводим данные к среднему 0 и стандартному отклонению 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Объединим закодированные города и числовые признаки\n",
        "X_train_full = np.hstack([X_train_encoded, X_train[['age']].values])\n",
        "X_test_full = np.hstack([X_test_encoded, X_test[['age']].values])\n",
        "\n",
        "# Масштабируем\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_full)\n",
        "X_test_scaled = scaler.transform(X_test_full)\n",
        "\n",
        "X_train_scaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Обучение модели и оценка качества\n",
        "Мы используем **Логистическую регрессию** для задачи классификации.\n",
        "\n",
        "Оценим качество по метрике **Accuracy** (доля правильных ответов)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Обучение модели\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Предсказания\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Оценка качества\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Задания для практики\n",
        "1. Объясните разницу между классификацией и регрессией на своих примерах.\n",
        "2. Загрузите свой датасет и разделите на Train/Test.\n",
        "3. Примените One-Hot Encoding к любому категориальному признаку.\n",
        "4. Масштабируйте данные с помощью MinMaxScaler и сравните с StandardScaler.\n",
        "5. Обучите модель и посчитайте метрику F1-score."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
