{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в Python для анализа данных\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Что можно делать в Python для анализа данных\n",
    "\n",
    "Python — универсальный язык программирования, который отлично подходит для обработки, анализа и визуализации данных. Вот несколько основных задач, которые можно решать с помощью Python:\n",
    "\n",
    "- Загрузка данных из разных источников (файлы, базы данных, API)\n",
    "- Очистка и подготовка данных к анализу\n",
    "- Исследовательский анализ данных (EDA)\n",
    "- Визуализация данных (графики, диаграммы)\n",
    "- Статистический анализ и построение моделей\n",
    "- Машинное обучение и прогнозирование\n",
    "\n",
    "Python имеет богатую экосистему библиотек, которые облегчают все эти задачи. В этом модуле познакомимся с двумя основными — **NumPy** и **Pandas**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Основные типы данных и преобразования\n",
    "\n",
    "В Python для аналитики часто используются следующие типы данных:\n",
    "\n",
    "| Тип данных | Описание                              | Пример                  |\n",
    "|------------|-------------------------------------|-------------------------|\n",
    "| `int`      | Целое число                         | `10`, `-5`              |\n",
    "| `float`    | Число с плавающей точкой (десятичное) | `3.14`, `-0.001`         |\n",
    "| `string`   | Строка текста                       | `\"Максим\"`, `\"data\"`    |\n",
    "| `datetime` | Дата и время                       | `2023-08-10 12:00:00`   |\n",
    "\n",
    "### Пример создания и преобразования типов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> 123\n",
      "<class 'float'> 10.0\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> 2023-08-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Создание переменных разных типов\n",
    "a = 10                  # int\n",
    "b = 3.14                # float\n",
    "c = \"123\"               # string\n",
    "d = \"2023-08-10\"        # string, представляющая дату\n",
    "\n",
    "# Преобразование string в int\n",
    "c_int = int(c)          # 123\n",
    "\n",
    "# Преобразование int в float\n",
    "a_float = float(a)      # 10.0\n",
    "\n",
    "# Работа с датами\n",
    "import pandas as pd\n",
    "d_datetime = pd.to_datetime(d)  # Преобразование строки в datetime\n",
    "\n",
    "print(type(c_int), c_int)\n",
    "print(type(a_float), a_float)\n",
    "print(type(d_datetime), d_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Как это работает:**  \n",
    "> Мы используем встроенные функции `int()`, `float()`, чтобы конвертировать данные между типами. Для преобразования строки с датой в формат `datetime` используем функцию `pd.to_datetime()` из библиотеки Pandas, которая понимает много форматов даты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Введение в NumPy и Pandas\n",
    "\n",
    "### NumPy\n",
    "\n",
    "NumPy — библиотека для работы с числовыми массивами. Основной объект — `ndarray` (массив).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Создаем массив из списка\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(arr)\n",
    "print(type(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Как это работает:**  \n",
    "> `np.array()` преобразует обычный список Python в эффективный массив NumPy, который позволяет быстро выполнять математические операции над большими объёмами чисел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "Pandas — библиотека для работы с табличными данными. Основные структуры — `Series` (одномерный массив) и `DataFrame` (таблица).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n",
      "     Имя  Возраст\n",
      "0    Аня       25\n",
      "1  Борис       30\n",
      "2   Вера       22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Создаем Series из списка\n",
    "s = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "# Создаем DataFrame из словаря\n",
    "data = {\n",
    "    'Имя': ['Аня', 'Борис', 'Вера'],\n",
    "    'Возраст': [25, 30, 22]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(s)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Как это работает:**  \n",
    "> `Series` похож на столбец в таблице, а `DataFrame` — на всю таблицу. Они поддерживают индексацию, фильтрацию, агрегацию и многое другое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Чтение данных — все основные способы\n",
    "\n",
    "### Чтение CSV файла\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "df_csv = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv')\n",
    "print(df_csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение Excel файла\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Для чтения Excel нужно установить пакет openpyxl: pip install openpyxl\u001b[39;00m\n\u001b[32m      2\u001b[39m df_dict = pd.read_excel(\u001b[33m'\u001b[39m\u001b[33monline_retail_II.xlsx\u001b[39m\u001b[33m'\u001b[39m, sheet_name=[\u001b[33m'\u001b[39m\u001b[33mYear 2009-2010\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mYear 2010-2011\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_dict\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m())\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# Для чтения Excel нужно установить пакет openpyxl: pip install openpyxl\n",
    "df_dict = pd.read_excel('online_retail_II.xlsx', sheet_name=['Year 2009-2010', 'Year 2010-2011'])\n",
    "print(df_dict.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение JSON файла\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Invoice StockCode                          Description  Quantity  \\\n",
      "0  489434     85048  15CM CHRISTMAS GLASS BALL 20 LIGHTS        12   \n",
      "1  489434    79323P                   PINK CHERRY LIGHTS        12   \n",
      "2  489434    79323W                  WHITE CHERRY LIGHTS        12   \n",
      "3  489434     22041         RECORD FRAME 7\" SINGLE SIZE         48   \n",
      "4  489434     21232       STRAWBERRY CERAMIC TRINKET BOX        24   \n",
      "\n",
      "          InvoiceDate  Price  Customer ID         Country  \n",
      "0 2009-12-01 07:45:00   6.95      13085.0  United Kingdom  \n",
      "1 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "2 2009-12-01 07:45:00   6.75      13085.0  United Kingdom  \n",
      "3 2009-12-01 07:45:00   2.10      13085.0  United Kingdom  \n",
      "4 2009-12-01 07:45:00   1.25      13085.0  United Kingdom  \n",
      "  Invoice StockCode                          Description  Quantity  \\\n",
      "0  536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
      "1  536365     71053                  WHITE METAL LANTERN         6   \n",
      "2  536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
      "3  536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
      "4  536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
      "\n",
      "          InvoiceDate  Price  Customer ID  Monetary  \n",
      "0 2010-12-01 08:26:00   2.55      17850.0     15.30  \n",
      "1 2010-12-01 08:26:00   3.39      17850.0     20.34  \n",
      "2 2010-12-01 08:26:00   2.75      17850.0     22.00  \n",
      "3 2010-12-01 08:26:00   3.39      17850.0     20.34  \n",
      "4 2010-12-01 08:26:00   3.39      17850.0     20.34  \n"
     ]
    }
   ],
   "source": [
    "df_json = pd.read_json('https://jsonplaceholder.typicode.com/posts')\n",
    "print(df_dict['Year 2009-2010'].head())\n",
    "print(df_dict['Year 2010-2011'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55fb6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_dict['Year 2009-2010']\n",
    "df2 = df_dict['Year 2010-2011']\n",
    "\n",
    "df_all = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение из SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f37230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id   name  age\n",
      "0   1    Аня   25\n",
      "1   2  Борис   30\n",
      "2   3   Вера   22\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Создаем соединение с временной базой в памяти\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# Создаем курсор для выполнения SQL-команд\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Создаем таблицу\n",
    "cursor.execute('''\n",
    "CREATE TABLE table_name (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    age INTEGER\n",
    ")\n",
    "''')\n",
    "\n",
    "# Вставляем данные\n",
    "cursor.executemany('INSERT INTO table_name (name, age) VALUES (?, ?)', [\n",
    "    ('Аня', 25),\n",
    "    ('Борис', 30),\n",
    "    ('Вера', 22),\n",
    "])\n",
    "\n",
    "# Фиксируем изменения\n",
    "conn.commit()\n",
    "\n",
    "# Считываем данные в DataFrame через Pandas\n",
    "df_sql = pd.read_sql_query('SELECT * FROM table_name', conn)\n",
    "\n",
    "print(df_sql)\n",
    "\n",
    "# Закрываем соединение\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(':memory:')  # создаём временную базу в памяти\n",
    "# Для демонстрации нужно создать таблицу и вставить данные, но здесь пример базового запроса\n",
    "df_sql = pd.read_sql_query('SELECT * FROM table_name', conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение Parquet и Pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e334d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.3.1\n",
      "pyarrow: 21.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"pyarrow:\", pyarrow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f84bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100000  # количество строк за раз\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv('yellow_tripdata_2015-01.csv', chunksize=chunk_size):\n",
    "    # тут можно делать обработку по частям, например фильтрацию\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Скачай CSV файл, например 'yellow_tripdata_2023-01.csv'\n",
    "df = pd.read_csv('yellow_tripdata_2015-01.csv')\n",
    "\n",
    "# Сохрани в Parquet (бинарный и быстрый формат)\n",
    "df.to_parquet('yellow_tripdata_2015-01.parquet', engine='pyarrow')\n",
    "\n",
    "# Теперь можешь читать Parquet-файл\n",
    "df_parquet = pd.read_parquet('yellow_tripdata_2015-01.parquet')\n",
    "print(df_parquet.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet\n",
    "df_parquet = pd.read_parquet('data.parquet')\n",
    "\n",
    "# Pickle\n",
    "df_pickle = pd.read_pickle('data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Первичный просмотр данных\n",
    "\n",
    "Основные методы для быстрого осмотра датасета:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "     survived  pclass     sex   age  sibsp  parch   fare embarked  class  \\\n",
      "888         0       3  female   NaN      1      2  23.45        S  Third   \n",
      "889         1       1    male  26.0      0      0  30.00        C  First   \n",
      "890         0       3    male  32.0      0      0   7.75        Q  Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "888  woman       False  NaN  Southampton    no  False  \n",
      "889    man        True    C    Cherbourg   yes   True  \n",
      "890    man        True  NaN   Queenstown    no   True  \n",
      "(891, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   survived     891 non-null    int64  \n",
      " 1   pclass       891 non-null    int64  \n",
      " 2   sex          891 non-null    object \n",
      " 3   age          714 non-null    float64\n",
      " 4   sibsp        891 non-null    int64  \n",
      " 5   parch        891 non-null    int64  \n",
      " 6   fare         891 non-null    float64\n",
      " 7   embarked     889 non-null    object \n",
      " 8   class        891 non-null    object \n",
      " 9   who          891 non-null    object \n",
      " 10  adult_male   891 non-null    bool   \n",
      " 11  deck         203 non-null    object \n",
      " 12  embark_town  889 non-null    object \n",
      " 13  alive        891 non-null    object \n",
      " 14  alone        891 non-null    bool   \n",
      "dtypes: bool(2), float64(2), int64(4), object(7)\n",
      "memory usage: 92.4+ KB\n",
      "None\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "survived         int64\n",
      "pclass           int64\n",
      "sex             object\n",
      "age            float64\n",
      "sibsp            int64\n",
      "parch            int64\n",
      "fare           float64\n",
      "embarked        object\n",
      "class           object\n",
      "who             object\n",
      "adult_male        bool\n",
      "deck            object\n",
      "embark_town     object\n",
      "alive           object\n",
      "alone             bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_csv.head())       # первые 5 строк\n",
    "print(df_csv.tail(3))      # последние 3 строки\n",
    "print(df_csv.shape)        # размер (строки, столбцы)\n",
    "print(df_csv.info())       # информация о типах и пропусках\n",
    "print(df_csv.describe())   # статистика по числовым колонкам\n",
    "print(df_csv.dtypes)       # типы данных по колонкам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Как это работает:**  \n",
    "> Эти методы позволяют быстро оценить структуру данных, проверить наличие пропущенных значений и типы столбцов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Подготовка данных до EDA\n",
    "\n",
    "### Переименование столбцов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.rename(columns={'survived': 'Выжил', 'age': 'Возраст'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение типов данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv['Возраст'] = df_csv['Возраст'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с пропусками\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выжил            0\n",
      "pclass           0\n",
      "sex              0\n",
      "Возраст          0\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Проверяем пропуски\n",
    "print(df_csv.isnull().sum())\n",
    "\n",
    "# Заполнение пропусков средним значением\n",
    "df_csv['Возраст'] = df_csv['Возраст'].fillna(df_csv['Возраст'].mean())\n",
    "\n",
    "# Удаление строк с пропусками\n",
    "df_csv.dropna(subset=['Возраст'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Мини-задания для закрепления\n",
    "\n",
    "1. Загрузите датасет Titanic с помощью `pd.read_csv()`. Просмотрите первые 10 строк.\n",
    "2. Определите типы данных в таблице и преобразуйте столбец с возрастом к типу float.\n",
    "3. Переименуйте столбцы `survived` и `age` на русский язык.\n",
    "4. Найдите и заполните пропуски в столбце с возрастом средним значением.\n",
    "5. Сохраните полученный DataFrame в файл формата CSV с именем `titanic_clean.csv`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
